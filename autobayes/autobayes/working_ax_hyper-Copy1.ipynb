{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb62339d-c9f6-4bd1-8a00-a416783336cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU automatically detected. Setting SETTINGS.GPU to 0, and SETTINGS.NJOBS to cpu_count.\n"
     ]
    }
   ],
   "source": [
    "from notears.locally_connected import LocallyConnected\n",
    "from notears.lbfgsb_scipy import LBFGSBScipy\n",
    "from notears.trace_expm import trace_expm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from notears.locally_connected import LocallyConnected\n",
    "from notears.lbfgsb_scipy import LBFGSBScipy\n",
    "from notears.trace_expm import trace_expm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import notears.utils as ut\n",
    "import cdt\n",
    "from metric import MetricsDAG\n",
    "from pgmpy.models import BayesianModel\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from ax.service.managed_loop import optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5976da-5f76-4e21-ab69-d5908e417728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.managed_loop import optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1986b44a-d279-4d75-af55-29d72cde606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, graph = cdt.data.load_dataset('sachs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f72e2d-652f-4aa5-bed6-9432bd205280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e1baea-2085-44b9-95f3-468455f84810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notears.nonlinear import NotearsMLP, notears_nonlinear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63cfbdec-65c0-4907-a6a0-7650366f783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_saches(train, parameterization):\n",
    "    torch.set_default_dtype(torch.double)\n",
    "    np.set_printoptions(precision=3)\n",
    "    ut.set_random_seed(123)\n",
    "\n",
    "    d= 11 # TODO Needs to change \n",
    "    model = NotearsMLP(dims=[d, 10, 1], bias=True)\n",
    "    global W_est\n",
    "    W_est = notears_nonlinear(model,\n",
    "                          train.to_numpy(), # Change to train\n",
    "                          lambda1=parameterization['lambda1'],\n",
    "                          lambda2=parameterization['lambda2'],\n",
    "                          max_iter=100,\n",
    "                          h_tol=1e-8,\n",
    "                          rho_max=1e+16,\n",
    "                          w_threshold=parameterization['w_threshold']\n",
    "    )\n",
    "    W_est_binary = W_est !=0\n",
    "    assert ut.is_dag(W_est)\n",
    "    return W_est_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a749dcac-d278-4272-a6cc-cd368d2a07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_given_parameter_config(parameterization: dict):\n",
    "    print('In the loop')\n",
    "    kfold = KFold(3, True, 1)\n",
    "    folds_score = []\n",
    "    for train_idx, test_idx in kfold.split(data):\n",
    "        train, test = data.iloc[train_idx, :], data.iloc[test_idx, :]\n",
    "\n",
    "        # 1. Find the estiamte dgraph using inner fold training data\n",
    "        weight_estimated = train_on_saches(train, parameterization)\n",
    "        sm = nx.convert_matrix.from_numpy_array(W_est != 0)\n",
    "\n",
    "        bn = BayesianModel()\n",
    "        bn.add_edges_from(sm.edges)\n",
    "        nodes = list(bn.nodes())\n",
    "        # 2. For each node, train a regression tree model and record its performance\n",
    "        score_list = []\n",
    "        for node in nodes:\n",
    "            markov_blanket = bn.get_markov_blanket(node)\n",
    "            \n",
    "            train_x, train_y = train.loc[:, markov_blanket], train.loc[:, node]\n",
    "            # Normalize train_x, train_y, test_x, test_y by scale of the training dataset\n",
    "            train_x=(train_x-train_x.mean())/train_x.std()\n",
    "            train_y=(train_y-train_y.mean())/train_y.std()\n",
    "            \n",
    "            test_x, test_y = test.loc[:, markov_blanket], test.loc[:, node]\n",
    "            test_x=(test_x-train_x.mean())/train_x.std()\n",
    "            test_y=(test_y-train_y.mean())/train_y.std()\n",
    "            \n",
    "            train_pool = Pool(train_x, train_y)\n",
    "\n",
    "            model = CatBoostRegressor(iterations=50, verbose=False)\n",
    "            model.fit(train_pool)\n",
    "            mse = mean_squared_error(model.predict(test_x), test_y)\n",
    "            print(f'MSE at Node {node} is = {mse}')\n",
    "            score_list.append(mse)\n",
    "        # 3. Average fold score of average score across nodes\n",
    "        fold_score = np.mean(score_list)\n",
    "        folds_score.append(fold_score)\n",
    "    avg_folds_score = np.mean(folds_score)\n",
    "    return avg_folds_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43e1b49c-1a13-480d-9578-5f8049f6b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_optimize(data):\n",
    "    best_parameters, best_values, experiment, model = optimize(\n",
    "            parameters=[\n",
    "              {\n",
    "                \"name\": \"lambda1\",\n",
    "                \"type\": \"range\",\n",
    "                \"bounds\": [0.01, 0.5],\n",
    "                \"log_scale\": True\n",
    "              },\n",
    "              {\n",
    "                 \"name\": \"lambda2\",\n",
    "                 \"type\": \"range\",\n",
    "                 \"bounds\": [0.01, 0.5],\n",
    "                 \"log_scale\": True\n",
    "              },\n",
    "              {\n",
    "                  \"name\": \"w_threshold\",\n",
    "                  \"type\": \"range\",\n",
    "                  \"bounds\": [0.01, 0.5],\n",
    "                  \"log_scale\": True\n",
    "               }\n",
    "            ],\n",
    "            # Booth function\n",
    "            evaluation_function=train_evaluate_given_parameter_config,\n",
    "            minimize=True,\n",
    "        )\n",
    "    return best_parameters, best_values, experiment, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c717d098-912c-48ae-a607-0905074cea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 12-02 13:14:19] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter lambda1. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 12-02 13:14:19] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter lambda2. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 12-02 13:14:19] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter w_threshold. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 12-02 13:14:19] ax.modelbridge.dispatch_utils: Using Bayesian optimization since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 12-02 13:14:19] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 6 trials, GPEI for subsequent trials]). Iterations after 6 will take longer to generate due to  model-fitting.\n",
      "[INFO 12-02 13:14:19] ax.service.managed_loop: Started full optimization with 20 steps.\n",
      "[INFO 12-02 13:14:19] ax.service.managed_loop: Running optimization trial 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR 12-02 14:26:37] ax.service.managed_loop: Encountered exception during optimization: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sheng\\anaconda3\\envs\\causalnex\\lib\\site-packages\\ax\\service\\managed_loop.py\", line 229, in full_run\n",
      "    self.run_trial()\n",
      "  File \"C:\\Users\\sheng\\anaconda3\\envs\\causalnex\\lib\\site-packages\\ax\\utils\\common\\executils.py\", line 147, in actual_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sheng\\anaconda3\\envs\\causalnex\\lib\\site-packages\\ax\\service\\managed_loop.py\", line 207, in run_trial\n",
      "    raw_data={\n",
      "  File \"C:\\Users\\sheng\\anaconda3\\envs\\causalnex\\lib\\site-packages\\ax\\service\\managed_loop.py\", line 208, in <dictcomp>\n",
      "    arm.name: self._call_evaluation_function(arm.parameters, weight)\n",
      "  File \"C:\\Users\\sheng\\anaconda3\\envs\\causalnex\\lib\\site-packages\\ax\\service\\managed_loop.py\", line 147, in _call_evaluation_function\n",
      "    evaluation = self.evaluation_function(parameterization)\n",
      "  File \"C:\\Users\\sheng\\AppData\\Local\\Temp/ipykernel_40560/651465630.py\", line 9, in train_evaluate_given_parameter_config\n",
      "    weight_estimated = train_on_saches(train, parameterization)\n",
      "  File \"C:\\Users\\sheng\\AppData\\Local\\Temp/ipykernel_40560/990641813.py\", line 19, in train_on_saches\n",
      "    assert ut.is_dag(W_est)\n",
      "AssertionError\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot identify best point if experiment contains no data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_40560/842266087.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mbayesian_optimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_40560/2810995501.py\u001b[0m in \u001b[0;36mbayesian_optimize\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbayesian_optimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     best_parameters, best_values, experiment, model = optimize(\n\u001b[0m\u001b[0;32m      3\u001b[0m             parameters=[\n\u001b[0;32m      4\u001b[0m               {\n\u001b[0;32m      5\u001b[0m                 \u001b[1;34m\"name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"lambda1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\causalnex\\lib\\site-packages\\ax\\service\\managed_loop.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(parameters, evaluation_function, experiment_name, objective_name, minimize, parameter_constraints, outcome_constraints, total_trials, arms_per_trial, random_seed, generation_strategy)\u001b[0m\n\u001b[0;32m    295\u001b[0m     )\n\u001b[0;32m    296\u001b[0m     \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m     \u001b[0mparameterization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparameterization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_current_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\causalnex\\lib\\site-packages\\ax\\service\\managed_loop.py\u001b[0m in \u001b[0;36mget_best_point\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;31m# Could not find through model, default to using raw objective.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         parameterization, values = get_best_raw_objective_point(\n\u001b[0m\u001b[0;32m    251\u001b[0m             \u001b[0mexperiment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\causalnex\\lib\\site-packages\\ax\\service\\utils\\best_point.py\u001b[0m in \u001b[0;36mget_best_raw_objective_point\u001b[1;34m(experiment, optimization_config)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mdat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot identify best point if experiment contains no data.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mScalarizedObjective\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot identify best point if experiment contains no data."
     ]
    }
   ],
   "source": [
    "best_parameters, values, experiment, model  = bayesian_optimize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "982f7275-1ab3-49e6-b93b-45638e81eb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda1': 0.13347911283786074,\n",
       " 'lambda2': 0.01,\n",
       " 'w_threshold': 0.025991817570101477}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb08fc3f-79cb-43cd-9a0b-c6aaf9f6153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notears.nonlinear import NotearsMLP, notears_nonlinear\n",
    "\n",
    "\n",
    "def train_on_saches(train, parameterization):\n",
    "    torch.set_default_dtype(torch.double)\n",
    "    np.set_printoptions(precision=3)\n",
    "    ut.set_random_seed(123)\n",
    "\n",
    "    d= 10\n",
    "    model = NotearsMLP(dims=[d, 10, 1], bias=True)\n",
    "    global W_est\n",
    "    W_est = notears_nonlinear(model,\n",
    "                          train.to_numpy(), # Change to train\n",
    "                          lambda1=parameterization['lambda1'],\n",
    "                          lambda2=parameterization['lambda2'],\n",
    "                          max_iter=100,\n",
    "                          h_tol=1e-8,\n",
    "                          rho_max=1e+16,\n",
    "                          w_threshold=parameterization['w_threshold']\n",
    "    )\n",
    "    W_est_binary = W_est !=0\n",
    "    assert ut.is_dag(W_est)\n",
    "    return W_est_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c0127e7-bf94-41eb-81d8-1c2c59e3cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "23d4b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pass shuffle=True, random_state=1 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "BayesianModel has been renamed to BayesianNetwork. Please use BayesianNewtork class, BayesianModel will be removed in future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE at Node 0 is = 1.0002795693903483\n",
      "MSE at Node 5 is = 2.642699904085316\n",
      "MSE at Node 1 is = 0.14025862376885628\n",
      "MSE at Node 6 is = 0.9136642209257972\n",
      "MSE at Node 2 is = 2.337938271621135\n",
      "MSE at Node 8 is = 1.1136731254378014\n",
      "MSE at Node 3 is = 2.7494904881783127\n",
      "MSE at Node 4 is = 5.792277352579166\n",
      "MSE at Node 7 is = 3.704561191788133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BayesianModel has been renamed to BayesianNetwork. Please use BayesianNewtork class, BayesianModel will be removed in future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE at Node 0 is = 1.2664815966612395\n",
      "MSE at Node 5 is = 6.3541927987466815\n",
      "MSE at Node 1 is = 0.13216892032337338\n",
      "MSE at Node 6 is = 0.7887898931635486\n",
      "MSE at Node 2 is = 2.3806958713255253\n",
      "MSE at Node 8 is = 1.4247255658673081\n",
      "MSE at Node 3 is = 4.627122627229899\n",
      "MSE at Node 4 is = 5.243977437147302\n",
      "MSE at Node 7 is = 6.4353894234641835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BayesianModel has been renamed to BayesianNetwork. Please use BayesianNewtork class, BayesianModel will be removed in future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE at Node 0 is = 1.8170542200009754\n",
      "MSE at Node 5 is = 9.628422426190236\n",
      "MSE at Node 1 is = 0.14348376869863189\n",
      "MSE at Node 6 is = 1.3764157380060549\n",
      "MSE at Node 2 is = 3.13248662628116\n",
      "MSE at Node 4 is = 4.187287071733469\n",
      "MSE at Node 8 is = 1.478422452018934\n",
      "MSE at Node 3 is = 10.730524498046723\n",
      "MSE at Node 7 is = 4.241254852045011\n"
     ]
    }
   ],
   "source": [
    "parameterization = {'lambda1': 0.1, 'lambda2': 0.1, 'w_threshold': 0.5}\n",
    "# prepare cross validation\n",
    "kfold = KFold(3, True, 1)\n",
    "folds_score = []\n",
    "# enumerate splits\n",
    "for train_idx, test_idx in kfold.split(data):\n",
    "    train, test = data.iloc[train_idx, :], data.iloc[test_idx, :]\n",
    "\n",
    "    # 1. Find the estiamte dgraph using inner fold training data\n",
    "    weight_estimated = train_on_saches(train, parameterization)\n",
    "    sm = nx.convert_matrix.from_numpy_array(W_est != 0)\n",
    "\n",
    "    bn = BayesianModel()\n",
    "    bn.add_edges_from(sm.edges)\n",
    "    nodes = list(bn.nodes())\n",
    "    # 2. For each node, train a regression tree model and record its performance\n",
    "    score_list = []\n",
    "    for node in nodes:\n",
    "        markov_blanket = bn.get_markov_blanket(node)\n",
    "        train_x, train_y = train.loc[:, markov_blanket], train.loc[:, node]\n",
    "        test_x, test_y = test.loc[:, markov_blanket], test.loc[:, node]\n",
    "        train_pool = Pool(train_x, train_y)\n",
    "        \n",
    "        model = CatBoostRegressor(iterations=50, verbose=False)\n",
    "        model.fit(train_pool)\n",
    "        mse = mean_squared_error(model.predict(test_x), test_y)\n",
    "        print(f'MSE at Node {node} is = {mse}')\n",
    "        score_list.append(mse)\n",
    "    # 3. Average fold score of average score across nodes\n",
    "    fold_score = np.mean(score_list)\n",
    "    folds_score.append(fold_score)\n",
    "avg_folds_score = np.mean(folds_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc577980-32e8-4133-82c4-219b28135376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1771755012861163"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_folds_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18872a5b-f64d-4241-910c-4059ed7a4a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5887e50c-46d1-4559-9e33-cc81aaa8bdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 1, 6, 2, 8, 3, 4, 7]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d3982e9-c9e1-4ca1-8f3c-5fafebec3754",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30840/1867691873.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_markov_blanket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "bn.get_markov_blanket(nodes[node_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56721f10-3db4-4dbf-808c-0bc3e2c007d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 101 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_x, train_y = train.loc[:, markov_blanket], train.loc[:, nodes[node_idx]]\n",
    "test_x, test_y = test.loc[:, markov_blanket], test.loc[:, nodes[node_idx]]\n",
    "train_pool = Pool(train_x, train_y)\n",
    "\n",
    "model = CatBoostRegressor(iterations = 100, verbose=False)\n",
    "model.fit(train_pool)\n",
    "score_list.append(mean_squared_error(model.predict(test_x), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ec847c3-616d-4379-89ee-7447492faea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0349892143886394"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(model.predict(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9af047f3-f214-4776-b266-2a4816783ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.207474</td>\n",
       "      <td>6.464077</td>\n",
       "      <td>2.092471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.458089</td>\n",
       "      <td>5.934889</td>\n",
       "      <td>2.098876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.796108</td>\n",
       "      <td>7.890693</td>\n",
       "      <td>5.622521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.808592</td>\n",
       "      <td>9.925525</td>\n",
       "      <td>-0.056029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.083932</td>\n",
       "      <td>13.307149</td>\n",
       "      <td>-1.235286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>11.610377</td>\n",
       "      <td>11.211398</td>\n",
       "      <td>2.923260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>14.556498</td>\n",
       "      <td>10.419711</td>\n",
       "      <td>4.606644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>9.852090</td>\n",
       "      <td>5.261232</td>\n",
       "      <td>1.996898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-0.872462</td>\n",
       "      <td>0.761941</td>\n",
       "      <td>-3.841677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>10.689388</td>\n",
       "      <td>7.953876</td>\n",
       "      <td>-0.790396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             3          4         5\n",
       "0    11.207474   6.464077  2.092471\n",
       "1    11.458089   5.934889  2.098876\n",
       "2     7.796108   7.890693  5.622521\n",
       "3    10.808592   9.925525 -0.056029\n",
       "6    10.083932  13.307149 -1.235286\n",
       "..         ...        ...       ...\n",
       "191  11.610377  11.211398  2.923260\n",
       "192  14.556498  10.419711  4.606644\n",
       "195   9.852090   5.261232  1.996898\n",
       "196  -0.872462   0.761941 -3.841677\n",
       "197  10.689388   7.953876 -0.790396\n",
       "\n",
       "[133 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:, markov_blanket]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41e7f47-e8aa-42e4-9d47-928e14e29e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
